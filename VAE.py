# -*- coding: utf-8 -*-
"""VAE_(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QgVCV9XKjqqxKpDCpRDTC1Ph0Af8hizz
"""

import numpy as np
import torch
import torch.nn as nn
from keras.datasets import mnist
from matplotlib import pyplot as plt
import math
from tqdm import tqdm
import torchvision
import torchvision.datasets

EPOCHS = 50
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODELS = []
BATCH_SIZE = 100

# (train_X, _), (test_X, _) = mnist.load_data()
# train_X = torch.from_numpy(train_X).float()
# test_X = torch.from_numpy(test_X).float()
# type(train_X)
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())
testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())

# trainset=trainset*2-1

plt.subplot()
plt.imshow(trainset[0][0].squeeze(0), cmap=plt.get_cmap('gray'))
plt.show()

#DataLoader
from torch.utils.data import DataLoader

train_dataloader = DataLoader(dataset = trainset,
                              batch_size = BATCH_SIZE,
                              shuffle = True)

test_dataloader = DataLoader(dataset = testset,
                              batch_size = BATCH_SIZE,
                              shuffle = False)

class LatentfromX(nn.Module):
    def __init__(self, input_channels, latent_dims):
        super().__init__()
        self.stack = nn.Sequential(
            # nn.Conv2d(in_channels=input_channels, out_channels=3, kernel_size=4),
            # nn.ReLU(),
            # nn.MaxPool2d(kernel_size=2),
            # nn.Conv2d(in_channels=3, out_channels=3, kernel_size=2),
            # nn.ReLU(),
            nn.Linear(in_features = input_channels, out_features = 256),
            nn.Tanh(),
            nn.Linear(in_features = 256, out_features = 64),
            nn.Tanh()
        )
        self.mean_layer = nn.Sequential(
            # nn.Flatten(),
            # nn.Linear(in_features=11 * 11 * 3, out_features=latent_dims),
            nn.Linear(in_features = 64, out_features = latent_dims),
            nn.Tanh()
        )
        self.log_var_layer = nn.Sequential(
            # nn.Flatten(),
            nn.Linear(in_features=64, out_features=latent_dims),
            nn.Tanh()
        )

    def forward(self, z):
        z = self.stack(z)
        return self.mean_layer(z), self.log_var_layer(z)

class ReconstructFromLatent(nn.Module):
    def __init__(self, latent_dims, output_dims):
        super().__init__()
        self.stack = nn.Sequential(
            nn.Linear(in_features=latent_dims, out_features=196),
            nn.Tanh(),
            nn.Linear(in_features=196, out_features=256),
            nn.Tanh(),
            nn.Linear(in_features=256, out_features=576),
            nn.Tanh(),
        )
        self.reconstruct = nn.Sequential(
            nn.Linear(in_features=576, out_features=output_dims),
            nn.Sigmoid(),
        )
        # self.mean_layer = nn.Sequential(
        #     nn.Linear(in_features=576, out_features=output_dims),
        #     nn.Tanh(),
        # )
        # self.log_std_layer = nn.Sequential(
        #     nn.Linear(in_features=576, out_features=output_dims),
        #     nn.Tanh(),
        # )

    def forward(self, x):
        x = self.stack(x)
        return self.reconstruct(x)

class VAE(nn.Module):
    def __init__(self, latent_dims):
        super().__init__()
        #q(z|x)
        self.qz_x = LatentfromX(input_channels=28*28, latent_dims=latent_dims)
        #p(x|z)
        self.px_z = ReconstructFromLatent(latent_dims=latent_dims, output_dims=28*28)

    def forward(self, x):
        z_mean, z_log_var = self.qz_x(x)
        # reparameterized = z_mean + (torch.exp(z_log_var * 0.5) * np.random.normal(0, 1))
        reparameterized = z_mean + (torch.exp(z_log_var * 0.5) * torch.randn_like(z_log_var).to(DEVICE))
        reconstructed_x = self.px_z(reparameterized)
        return z_mean, z_log_var, reconstructed_x

reconstruction_error_history = []
kl_div_error_history= []
total_error_history = []
for i in range(6):
  reconstruction_error_history.append([])
  kl_div_error_history.append([])
  total_error_history.append([])
  latent_dims = 2**(i+1)
  VAEModel = VAE(latent_dims=latent_dims).to(DEVICE)
  optimizer = torch.optim.Adam(params=VAEModel.parameters(), lr=1e-3)
  loss_fn = nn.MSELoss(reduction="sum")
  VAEModel.train()
  for epoch in (range(EPOCHS)):
      loss=0
      total_reconstruction_error = 0
      total_kl_div_error = 0
      total_error = 0
      for batch, (x,y) in tqdm(enumerate(train_dataloader)):
          # x=2*x-1
          # print(x.shape)
          x=x.view(BATCH_SIZE, 28*28).to(DEVICE)
          z_mean, z_log_var, reconstructed_x = VAEModel(x.to(DEVICE))
          # print(x.flatten(start_dim=1).shape, reconstructed_x.shape)
          reconstruction_error = loss_fn(reconstructed_x.to(DEVICE), x.flatten(start_dim=1).to(DEVICE))
          # print(reconstruction_error.shape)
          # kl_div_error = torch.mean(0.5*torch.sum(torch.exp(z_log_var) + z_mean**2 -1 - z_log_var, dim=-1))
          kl_div_error = torch.sum(0.5*torch.sum(torch.exp(z_log_var) + z_mean**2 -1 - z_log_var, dim=-1))
          # print(kl_div_error.shape, reconstruction_error.shape)
          # loss=reconstruction_error+0.00001*kl_div_error
          loss=reconstruction_error+kl_div_error

          total_reconstruction_error += reconstruction_error
        #   print(reconstruction_error, kl_div_error)
          total_kl_div_error += torch.mean(kl_div_error).item()

          optimizer.zero_grad()
          # print(loss.shape)
          loss.backward()
          optimizer.step()

    #   total_reconstruction_error/=len(trainset)
    #   total_kl_div_error/=len(trainset)
      total_error = total_reconstruction_error + total_kl_div_error

      reconstruction_error_history[i].append(total_reconstruction_error)
      kl_div_error_history[i].append(total_kl_div_error)
      total_error_history[i].append(total_error)

      print(f"\nlatent_dim: {latent_dims} | epoch: {epoch+1} | re_loss: {total_reconstruction_error:.2f} | kl_div: {total_kl_div_error:.2f} | loss: {total_error:.2f}")
  MODELS.append(VAEModel)

fig = plt.figure(figsize = (13, 13))
rows, cols = 7, 5

test_features_batch, test_labels_batch = next(iter(test_dataloader))
for j in range(5):
  fig.add_subplot(rows, cols, j+1)
  plt.imshow(test_features_batch[j].squeeze(), cmap="gray")
  plt.title("Original")
  plt.axis(False)
  plt.subplots_adjust(hspace=0.4)

plt.savefig('plot_og.png')
for k,model in enumerate(MODELS):
  model.eval()

  with torch.inference_mode():
    _,_,re_x = model(test_features_batch.flatten(start_dim=1).to(DEVICE))

  for j in range(5):
    re_x_shaped=re_x[j].reshape(28,28)

    fig.add_subplot(rows, cols, (k+1)*5+(j+1))
    plt.imshow(re_x_shaped.detach().to("cpu").numpy(), cmap="gray")
    plt.title(f"Latent dimensions = {2**(k+1)}")
    plt.axis(False)
    plt.subplots_adjust(bottom=0.1, top=0.9)

plt.tight_layout()
plt.savefig('plot.png')

def mse(y_true, y_pred):
    return np.mean((y_true - y_pred)**2)

mse_vals=[]
test_dataloader = DataLoader(dataset = testset,
                              batch_size = BATCH_SIZE,
                              shuffle = False)

for model in MODELS:
  model.eval()
  mse_val=0
  with torch.inference_mode():
    for x_test, y in test_dataloader:
      _,_,re_x_test = model(x_test.flatten(start_dim=1).to(DEVICE))

      x_test_flat = x_test.flatten().to("cpu").numpy()
      re_x_test_flat = re_x_test.flatten().detach().to("cpu").numpy()

      mse_val += mse(x_test_flat, re_x_test_flat)


  mse_val /= len(test_dataloader)
  mse_vals.append(mse_val)

print(f"MSE values are = {mse_vals}")

plt.plot(mse_vals, label='Data 1', marker='o')

# Create a line graph for the second list
plt.plot(mse_vals, label='Data 2', marker='x')

# Add labels and title
plt.xlabel('Latent Dimensions')
plt.ylabel('MSE Loss')
plt.title('')
plt.xticks(range(1, 7), [2**(i+1) for i in range(1, 7)])

plt.legend()

# Show the plot
plt.show()

